from __future__ import annotations
from datetime import datetime
from pathlib import Path
import argparse
import os
import sys
import pandas as pd
import torch

from autogluon.tabular import TabularPredictor

# Meta columns ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏£‡∏ô (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Model ‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ñ‡∏•‡∏∑‡πà‡∏ô)
COLS_TO_DROP = ['force_mA', 'range_V', 'temp_C','wave_id']
ts = datetime.now().strftime("%Y%m%d_%H%M%S")
DEFAULT_SAVE_PATH = f"AutogluonModels/ag-{ts}"

def train(
    data_path: str,
    label: str = "wait_time_ms",
    model_dir: str | None = None,
    presets: str = "medium_quality",
    time_limit: int = 60,
) -> None:
    if not os.path.exists(data_path):
        raise FileNotFoundError(f'Input file not found: "{data_path}"')

    df = pd.read_csv(data_path)
    
    # --- 1. PREPROCESSING ---
    cols_to_drop_found = [c for c in COLS_TO_DROP if c in df.columns]
    if cols_to_drop_found:
        print(f"Dropping meta columns: {cols_to_drop_found}")
        df = df.drop(columns=cols_to_drop_found)

    df = df.dropna(subset=[label]).reset_index(drop=True)
    
    save_path = model_dir or DEFAULT_SAVE_PATH
    gpu_count = 1 if torch.cuda.is_available() else 0
    print(f"üöÄ Training device: {'GPU (CUDA)' if gpu_count > 0 else 'CPU'}")

    # --- 2. FIT MODEL ---
    predictor = TabularPredictor(
        label=label,
        path=save_path,
        problem_type="regression",
        eval_metric="mean_absolute_error",
        verbosity=2,
    ).fit(
        train_data=df,
        presets=presets,
        time_limit=time_limit,
        num_gpus=gpu_count,
    )

    # --- 3. MODEL ANALYSIS (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ADJUST MODEL) ---
    print("\n" + "="*60)
    print("üîç DEEP MODEL ANALYSIS & DIAGNOSIS")
    print("="*60)

    # A. Feature Importance: ‡∏î‡∏π‡∏ß‡πà‡∏≤ AI ‡πÉ‡∏ä‡πâ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÑ‡∏´‡∏ô‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Adjust)
    print("\n[1] Calculating Feature Importance...")
    importance = predictor.feature_importance(df)
    print(importance.head(15)) # ‡πÇ‡∏ä‡∏ß‡πå 15 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å

    # B. Leaderboard: ‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô‡∏â‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    print("\n[2] Model Leaderboard:")
    leaderboard = predictor.leaderboard(df, silent=True)
    print(leaderboard[["model", "score_val", "pred_time_val", "fit_time"]].head(5))

    # C. Residual Analysis: ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ó‡∏≤‡∏¢‡∏û‡∏•‡∏≤‡∏î (Worst Case)
    X_test = df.drop(columns=[label])
    y_actual = df[label]
    y_pred = predictor.predict(X_test)

    out = df.copy()
    out["pred_wait_time_ms"] = y_pred
    out["error_ms"] = out["pred_wait_time_ms"] - y_actual
    out["abs_error_ms"] = out["error_ms"].abs()

    # ‡∏î‡∏∂‡∏á 10 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà AI ‡∏ó‡∏≤‡∏¢‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå
    worst_10 = out.sort_values(by="abs_error_ms", ascending=False).head(10)
    print("\n[3] TOP 10 WORST PREDICTIONS (Review these Wave IDs!):")
    print(worst_10[["wave_id", label, "pred_wait_time_ms", "error_ms"]])

    # --- 4. SAVE DIAGNOSIS DATA ---
    os.makedirs("data/processed/analysis", exist_ok=True)
    os.makedirs("data/processed/train", exist_ok=True)

    # ‡πÑ‡∏ü‡∏•‡πå Diagnosis: ‡∏£‡∏ß‡∏° Features + Actual + Pred + Error (‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ Adjust ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå)
    diag_path = f"data/processed/analysis/diagnosis_report_{ts}.csv"
    out.to_csv(diag_path, index=False)

    # ‡πÑ‡∏ü‡∏•‡πå Feature Importance: ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏ï‡∏±‡∏î‡∏≠‡∏≠‡∏Å
    feat_imp_path = f"data/processed/analysis/feature_importance_{ts}.csv"
    importance.to_csv(feat_imp_path)

    # ‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏õ‡∏Å‡∏ï‡∏¥
    train_out_path = f"data/processed/train/train_with_predictions_{ts}.csv"
    out.drop(columns=["abs_error_ms"]).to_csv(train_out_path, index=False)

    print(f"\n‚úÖ Analysis Report Saved: {diag_path}")
    print(f"‚úÖ Feature Importance Saved: {feat_imp_path}")
    print(f"‚úÖ Model saved at: {save_path}")
    print("="*60)

def predict(
    model_path: str,
    input_csv: str,
    out_csv: str = "predictions.csv",
) -> None:
    if not os.path.exists(model_path):
        raise FileNotFoundError(f'Model not found at: "{model_path}"')
    
    print(f"üîÆ Loading model and predicting: {input_csv}")
    predictor = TabularPredictor.load(model_path)
    df = pd.read_csv(input_csv)

    # Clean meta columns
    for c in COLS_TO_DROP:
        if c in df.columns:
            df = df.drop(columns=[c])

    preds = predictor.predict(df)
    out = df.copy()
    out["pred_wait_time_ms"] = preds

    # Reorder columns ‡πÉ‡∏´‡πâ ID ‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏ó‡∏≤‡∏¢‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏∏‡∏î
    first_cols = ["wave_id", "pred_wait_time_ms"]
    other_cols = [c for c in out.columns if c not in first_cols]
    out = out[first_cols + other_cols]

    os.makedirs(os.path.dirname(out_csv) or '.', exist_ok=True)
    out.to_csv(out_csv, index=False)
    print(f"‚úÖ Prediction Results saved: {out_csv}")

def main():
    ap = argparse.ArgumentParser(description="AutoGluon Workflow with Analysis")
    ap.add_argument("--mode", default="train", choices=["train", "predict"])
    ap.add_argument("--data", default="data/processed/train/train_features.csv")
    ap.add_argument("--label", default="wait_time_ms")
    ap.add_argument("--model-path", default=None) # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î predict
    ap.add_argument("--inference-csv", default="data/processed/inference/features_test_2.csv")
    ap.add_argument("--out", default="data/processed/prediction/final_results.csv")
    ap.add_argument("--time-limit", type=int, default=120) # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    ap.add_argument("--presets", default="medium_quality")

    args = ap.parse_args()

    try:
        if args.mode == "train":
            train(
                data_path=args.data,
                label=args.label,
                presets=args.presets,
                time_limit=args.time_limit
            )
        else:
            if not args.model_path:
                print("‚ùå Error: Please specify --model-path for prediction mode.")
                return
            predict(
                model_path=args.model_path,
                input_csv=args.inference_csv,
                out_csv=args.out
            )
    except Exception as e:
        print(f"üí• ERROR: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()